{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: dataset information<br>\n",
    "show data images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io as scio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = scio.loadmat('VehicleInfo.mat')\n",
    "def alter(mat,path,object):\n",
    "    info = mat.get('VehicleInfo')\n",
    "    s = os.listdir(path)\n",
    "    count = 1\n",
    "    for i in sorted(s):\n",
    "        base = os.path.basename(i)\n",
    "        fileName = os.path.splitext(base)[0]\n",
    "        result = []\n",
    "        document = os.path.join(path,i)\n",
    "        img = cv2.imread(document)\n",
    "        if img is not None:\n",
    "            left = info[count-2][0][3][0][0][0][0][0]\n",
    "            top = info[count-2][0][3][0][0][1][0][0]\n",
    "            right = info[count-2][0][3][0][0][2][0][0]\n",
    "            bottom = info[count-2][0][3][0][0][3][0][0]\n",
    "            img = img[top:bottom,left:right] \n",
    "            img = cv2.resize(img,(299,299))\n",
    "        elif img is None:\n",
    "            print('title')\n",
    "        cv2.imwrite(object+os.sep+'%s.jpg' % fileName, img)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alter(mat,'BITVehicle_Dataset','Dataset_Resize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image data and label information.<br>\n",
    "Convert images and labels into numpy array.<br>\n",
    "Spilt the data for train and test randomly.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list = []\n",
    "for filename in sorted(os.listdir('./Dataset_Resize/')):\n",
    "    img = image.load_img(Path('./Dataset_Resize/', filename)) # load image data\n",
    "    X_list.append(image.img_to_array(img))\n",
    "X = np.array(X_list) # convert image to nparray\n",
    "\n",
    "df = pd.read_csv('./vehicles.csv', index_col=0) # load annotation file\n",
    "df_dummy = pd.get_dummies(df['Vehicle_Type']) # dummy encoding\n",
    "Y = np.array(df_dummy)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2) # splite data for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Introduce how to build aws enviroment<br>\n",
    "a machine with Keras, TensorFlow installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a baseline CNN (from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We try to train one small CNN with a few layers and few filters per layer on our data, as an initial baseline refering to Keras offical examples<sup>[1]</sup> which is a VGG-like convnet and we resize the image to 32x32 in order to train it on our own computer cpu.</p>\n",
    "<p>A convnet takes an image expressed as an array of numbers, applies a series of operations to that array and, at the end, returns the probability that an object in the image belongs to a particular class of objects. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Introduce each layer<br>\n",
    "This shallow CNN has 4 convolutional layers and uses ReLU(rectified linear units) activation function. And it uses maxpooling layers to down samples and dropout layers to reduce overfitting by a layer from seeing twice the exact same pattern.\n",
    "In the first block, in the convolutional layers, there are 3 filters and the kernal size is 3x3, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_1(input_shape):\n",
    "    model = Sequential()\n",
    "    # input: 32x32 images with 3 channels -> (32, 32, 3) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, name='Conv1-1'))\n",
    "    model.add(Activation('relu', name='ReLU1-1'))\n",
    "    model.add(Conv2D(32, (3, 3), name='Conv1-2'))\n",
    "    model.add(Activation('relu', name='ReLU1-2'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), name='MaxPool1'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks Method in Keras:<br>\n",
    "TODO: Introduce callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_Stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    verbose=0, \n",
    "    mode='auto'\n",
    ")\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "checkpointer = ModelCheckpoint(filepath=\"CNN.hdf5\", verbose=1)\n",
    "csv = CSVLogger('CNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = get_model_1((32, 32, 3))\n",
    "model.fit(X_train, \n",
    "          Y_train,\n",
    "          batch_size=256,\n",
    "          epochs=20,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[early_Stopping,reduceLR,checkpointer,csv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train result -> [Baseline CNN Model on Keras](./Keras Build CNN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://keras.io/getting-started/sequential-model-guide/#examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The code in the document by Junhan Ma, Bo Han is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
